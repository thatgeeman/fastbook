{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision.all import *\n",
    "import seaborn as sns\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#downloading the MNIST dataset\n",
    "path = untar_data(URLs.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Path('/storage/data/mnist_png'),\n",
       " (#2) [Path('/storage/data/mnist_png/training'),Path('/storage/data/mnist_png/testing')])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path, path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([60000, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the training datasets ready\n",
    "'''\n",
    "Important info:\n",
    "#training images = 60,000\n",
    "Each of the categories having roughly equal distribution: train_y.unique(return_counts=True)\n",
    "'''\n",
    "train_images_list = get_image_files(path/'training')\n",
    "train_x_list = [tensor(Image.open(img_path)) for img_path in train_images_list]\n",
    "train_y_list = [int(img_path.parent.name) for img_path in train_images_list]\n",
    "train_x = (torch.stack(train_x_list).float()/255).view(-1,28*28)\n",
    "train_y = tensor(train_y_list).view(-1,1)\n",
    "\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "train_dset = list(zip(train_x, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 784]), torch.Size([10000, 1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the validation datasets ready\n",
    "'''\n",
    "Important info:\n",
    "#validation images = 10,000\n",
    "Each of the categories having roughly equal distribution: valid_y.unique(return_counts=True)\n",
    "'''\n",
    "valid_images_list = get_image_files(path/'testing')\n",
    "valid_x_list = [tensor(Image.open(img_path)) for img_path in valid_images_list]\n",
    "valid_y_list = [int(img_path.parent.name) for img_path in valid_images_list]\n",
    "valid_x = (torch.stack(valid_x_list).float()/255).view(-1,28*28)\n",
    "valid_y = tensor(valid_y_list).view(-1,1)\n",
    "\n",
    "valid_x.shape, valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dset = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### Using fastai packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.090940</td>\n",
       "      <td>3.860469</td>\n",
       "      <td>0.983300</td>\n",
       "      <td>02:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = ImageDataLoaders.from_folder(path, train='training',valid='testing')\n",
    "learn = cnn_learner(dls, resnet18, pretrained=False,\n",
    "                    loss_func=F.cross_entropy, metrics=accuracy, n_out=10)\n",
    "learn.fit_one_cycle(1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### Manual SGD & Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dset, batch_size=64)\n",
    "#valid_dl = DataLoader(valid_dset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# function to calculate loss\n",
    "def mnist_loss(pred, actual):\n",
    "    l = nn.CrossEntropyLoss()\n",
    "    return l(pred, actual.squeeze())\n",
    "\n",
    "# function to calculate gradient\n",
    "def calc_grad(xb, yb, model):\n",
    "    pred = model(xb)\n",
    "    loss = mnist_loss(pred, yb)\n",
    "    loss.backward()    \n",
    "    return loss\n",
    "\n",
    "# function to define accuracy\n",
    "def batch_accuracy(pred, actual):\n",
    "    digit_pred = pred.max(dim=1)[1]\n",
    "    return (digit_pred==actual).float().mean()\n",
    "\n",
    "#function to train 1 epoch and print average batch loss\n",
    "def train_epoch(model):\n",
    "    batch_loss = []\n",
    "    for xb,yb in train_dl:\n",
    "        batch_loss.append(calc_grad(xb, yb, model))\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    print('Average batch loss: ', tensor(batch_loss).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#Simple 2 activations function NN\n",
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1007)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random accuracy\n",
    "batch_accuracy(simple_net(valid_x),valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "opt = BasicOptim(simple_net.parameters(), lr=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#function to train model for multiple epochs\n",
    "def train_model(model,epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print('epoch', i, ': ', batch_accuracy(model(valid_x),valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average batch loss:  tensor(0.2343)\n",
      "epoch 0 :  tensor(0.0974)\n",
      "Average batch loss:  tensor(0.2014)\n",
      "epoch 1 :  tensor(0.0974)\n",
      "Average batch loss:  tensor(0.1632)\n",
      "epoch 2 :  tensor(0.0974)\n",
      "Average batch loss:  tensor(0.1209)\n",
      "epoch 3 :  tensor(0.0975)\n",
      "Average batch loss:  tensor(0.1023)\n",
      "epoch 4 :  tensor(0.0976)\n",
      "Average batch loss:  tensor(0.0945)\n",
      "epoch 5 :  tensor(0.0978)\n",
      "Average batch loss:  tensor(0.0923)\n",
      "epoch 6 :  tensor(0.0980)\n",
      "Average batch loss:  tensor(0.0886)\n",
      "epoch 7 :  tensor(0.0981)\n",
      "Average batch loss:  tensor(0.0863)\n",
      "epoch 8 :  tensor(0.0985)\n",
      "Average batch loss:  tensor(0.0815)\n",
      "epoch 9 :  tensor(0.0986)\n",
      "Average batch loss:  tensor(0.0753)\n",
      "epoch 10 :  tensor(0.0987)\n",
      "Average batch loss:  tensor(0.0694)\n",
      "epoch 11 :  tensor(0.0988)\n",
      "Average batch loss:  tensor(0.0665)\n",
      "epoch 12 :  tensor(0.0988)\n",
      "Average batch loss:  tensor(0.0667)\n",
      "epoch 13 :  tensor(0.0989)\n",
      "Average batch loss:  tensor(0.0653)\n",
      "epoch 14 :  tensor(0.0990)\n",
      "Average batch loss:  tensor(0.0647)\n",
      "epoch 15 :  tensor(0.0990)\n",
      "Average batch loss:  tensor(0.0636)\n",
      "epoch 16 :  tensor(0.0989)\n",
      "Average batch loss:  tensor(0.0619)\n",
      "epoch 17 :  tensor(0.0990)\n",
      "Average batch loss:  tensor(0.0604)\n",
      "epoch 18 :  tensor(0.0991)\n",
      "Average batch loss:  tensor(0.0571)\n",
      "epoch 19 :  tensor(0.0989)\n",
      "Average batch loss:  tensor(0.0554)\n",
      "epoch 20 :  tensor(0.0986)\n",
      "Average batch loss:  tensor(0.0531)\n",
      "epoch 21 :  tensor(0.0983)\n",
      "Average batch loss:  tensor(0.0516)\n",
      "epoch 22 :  tensor(0.0982)\n",
      "Average batch loss:  tensor(0.0494)\n",
      "epoch 23 :  tensor(0.0983)\n",
      "Average batch loss:  tensor(0.0476)\n",
      "epoch 24 :  tensor(0.0983)\n",
      "Average batch loss:  tensor(0.0476)\n",
      "epoch 25 :  tensor(0.0984)\n",
      "Average batch loss:  tensor(0.0469)\n",
      "epoch 26 :  tensor(0.0985)\n",
      "Average batch loss:  tensor(0.0454)\n",
      "epoch 27 :  tensor(0.0985)\n",
      "Average batch loss:  tensor(0.0439)\n",
      "epoch 28 :  tensor(0.0985)\n",
      "Average batch loss:  tensor(0.0426)\n",
      "epoch 29 :  tensor(0.0986)\n",
      "Average batch loss:  tensor(0.0413)\n",
      "epoch 30 :  tensor(0.0987)\n",
      "Average batch loss:  tensor(0.0402)\n",
      "epoch 31 :  tensor(0.0986)\n",
      "Average batch loss:  tensor(0.0399)\n",
      "epoch 32 :  tensor(0.0985)\n",
      "Average batch loss:  tensor(0.0386)\n",
      "epoch 33 :  tensor(0.0985)\n",
      "Average batch loss:  tensor(0.0374)\n",
      "epoch 34 :  tensor(0.0986)\n",
      "Average batch loss:  tensor(0.0366)\n",
      "epoch 35 :  tensor(0.0988)\n",
      "Average batch loss:  tensor(0.0359)\n",
      "epoch 36 :  tensor(0.0988)\n",
      "Average batch loss:  tensor(0.0348)\n",
      "epoch 37 :  tensor(0.0989)\n",
      "Average batch loss:  tensor(0.0334)\n",
      "epoch 38 :  tensor(0.0989)\n",
      "Average batch loss:  tensor(0.0319)\n",
      "epoch 39 :  tensor(0.0989)\n",
      "Average batch loss:  tensor(0.0305)\n",
      "epoch 40 :  tensor(0.0988)\n",
      "Average batch loss:  tensor(0.0293)\n",
      "epoch 41 :  tensor(0.0988)\n",
      "Average batch loss:  tensor(0.0287)\n",
      "epoch 42 :  tensor(0.0988)\n",
      "Average batch loss:  tensor(0.0279)\n",
      "epoch 43 :  tensor(0.0987)\n",
      "Average batch loss:  tensor(0.0272)\n",
      "epoch 44 :  tensor(0.0988)\n",
      "Average batch loss:  tensor(0.0265)\n",
      "epoch 45 :  tensor(0.0988)\n",
      "Average batch loss:  tensor(0.0254)\n",
      "epoch 46 :  tensor(0.0988)\n",
      "Average batch loss:  tensor(0.0242)\n",
      "epoch 47 :  tensor(0.0988)\n",
      "Average batch loss:  tensor(0.0233)\n",
      "epoch 48 :  tensor(0.0989)\n",
      "Average batch loss:  tensor(0.0227)\n",
      "epoch 49 :  tensor(0.0989)\n",
      "Average batch loss:  tensor(0.0220)\n",
      "epoch 50 :  tensor(0.0989)\n",
      "Average batch loss:  tensor(0.0212)\n",
      "epoch 51 :  tensor(0.0990)\n",
      "Average batch loss:  tensor(0.0205)\n",
      "epoch 52 :  tensor(0.0990)\n",
      "Average batch loss:  tensor(0.0199)\n",
      "epoch 53 :  tensor(0.0990)\n",
      "Average batch loss:  tensor(0.0192)\n",
      "epoch 54 :  tensor(0.0990)\n",
      "Average batch loss:  tensor(0.0185)\n",
      "epoch 55 :  tensor(0.0990)\n",
      "Average batch loss:  tensor(0.0179)\n",
      "epoch 56 :  tensor(0.0990)\n",
      "Average batch loss:  tensor(0.0173)\n",
      "epoch 57 :  tensor(0.0991)\n",
      "Average batch loss:  tensor(0.0168)\n",
      "epoch 58 :  tensor(0.0991)\n",
      "Average batch loss:  tensor(0.0162)\n",
      "epoch 59 :  tensor(0.0992)\n"
     ]
    }
   ],
   "source": [
    "#model training call\n",
    "train_model(simple_net,60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
